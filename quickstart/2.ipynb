{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Great! There are plenty of outdoor activities you can try. Here are a few suggestions:\\n\\n1. Hiking: Go explore a nearby trail or park. It's a great way to connect with nature and get some exercise.\\n\\n2. Cycling: Dust off your bicycle and go for a ride. You can explore your neighborhood or find a scenic route in your city.\\n\\n3. Picnic: Pack a delicious lunch and head to a nearby park or beach. Enjoy the fresh air while having a relaxing meal.\\n\\n4. Gardening: If you have a green thumb, spend some time in your garden. Plant new flowers or vegetables, or simply tend to your existing plants.\\n\\n5. Kayaking or canoeing: If there's a lake or river nearby, rent a kayak or canoe and enjoy a peaceful day on the water.\\n\\n6. Camping: Plan a camping trip with friends or family. Spend a night or two in the great outdoors, roasting marshmallows and stargazing.\\n\\n7. Geocaching: Try geocaching, a modern-day treasure hunt using GPS coordinates. It's a fun and adventurous way to explore new areas.\\n\\n8. Outdoor photography: Grab your camera or smartphone and go for a photography walk. Capture the beauty of nature or interesting sights in your city.\\n\\n9. Beach day: If you live near the coast, spend a day at the beach. Swim, relax in the sun, and maybe even try some beach sports like volleyball or frisbee.\\n\\n10. Outdoor yoga or meditation: Find a peaceful spot in nature and practice yoga or meditation. It's a great way to relax, rejuvenate, and connect with your surroundings.\\n\\nRemember to check the weather forecast and dress appropriately for the activity you choose. Enjoy your time outdoors!\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([SystemMessage(content = \"You are a helpful assistant that helps a user figure out what activity to do\"),\n",
    "      HumanMessage(content=\"I am bored and don't know what to do, I like outdoor activities\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='This is my document', metadata={'my_doc_id': 1234, 'my_doc_title': 'My Document Title'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document(page_content=\"This is my document\", \n",
    "         metadata={'my_doc_id': 1234,\n",
    "            'my_doc_title': 'My Document Title'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lanuage model \n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='davinci-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Does the universe has meaning or it is meaningless? Is life all about suffering? Is there a meaning to life? Or is this life just a game? Is life a journey to the truth? Is life a one time experience? Or is it a cycle? Why am I here? What is my purpose? What is my duty? These are some questions that are asked by many people. What is the answer to all of these questions? Is there any answer? Is there any meaning to life? What is the purpose of life? What is truth? What is the truth about life? Can we know the answer to these questions? If you are looking for answers to these questions, you are at the right place. In this article, we are going to discuss the answers to these questions. Firstly, What is the meaning of life? This is one of the most important questions asked by many people. What is the meaning of life? Is there a meaning to life? Or is this life just a game? Is life a journey to the truth? Is life a one time experience? Or is it a cycle? Why am I here? What is my purpose? What is my duty? These are some questions that are asked by many people. What is the answer to all\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"what is the meaning of life?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Well, have you tried using a teleportation device? Just make sure to double-check the coordinates, unless you want to end up in New Pork instead.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are an unhelpful AI bot that makes a joke at whatever the user says\"),\n",
    "        HumanMessage(content=\"I would like to go to New York, how should I do this?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a sample: [-0.00019600906371495044, -0.0031846734422911354, -0.0007734206914647712, -0.019472001962491225, -0.01509231901785424]...\n",
      "Your embedding is length 1536\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi! It's time for the beach\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "print (f\"Here's a sample: {text_embedding[:5]}...\")\n",
    "print (f\"Your embedding is length {len(text_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function_call': {'arguments': '{\\n  \"location\": \"Boston, MA\",\\n  \"unit\": \"fahrenheit\"\\n}', 'name': 'get_current_weather'}}\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo-0613', temperature=1)\n",
    "\n",
    "output = chat(messages=\n",
    "     [\n",
    "         SystemMessage(content=\"You are an helpful AI bot\"),\n",
    "         HumanMessage(content=\"What’s the weather like in Boston right now?\")\n",
    "     ],\n",
    "     functions=[{\n",
    "         \"name\": \"get_current_weather\",\n",
    "         \"description\": \"Get the current weather in a given location\",\n",
    "         \"parameters\": {\n",
    "             \"type\": \"object\",\n",
    "             \"properties\": {\n",
    "                 \"location\": {\n",
    "                     \"type\": \"string\",\n",
    "                     \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                 },\n",
    "                 \"unit\": {\n",
    "                     \"type\": \"string\",\n",
    "                     \"enum\": [\"fahrenheit\"]\n",
    "                 }\n",
    "             },\n",
    "             \"required\": [\"location\", \"unit\"]\n",
    "         }\n",
    "     }\n",
    "     ]\n",
    ")\n",
    "print(output.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Boston, MA', 'unit': 'fahrenheit'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "output.additional_kwargs['function_call']['arguments']\n",
    "json.loads(output.additional_kwargs['function_call']['arguments'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I really want to do surfing today. How do I get started?\n",
      "I live in Seattle.\n",
      "\n",
      "****************************************\n",
      "LLM: posted by beccaj to Sports, Hobbies, & Recreation (23 answers total) 3 users marked this as a favorite\n",
      "\n",
      "It's your lucky day! You can take a class at Alki Beach, which is right in West Seattle. It's $35 for a 2 hour lesson, and you just show up with a swimsuit and a towel. They also have kayaking, stand up paddle boarding, and wind surfing.\n",
      "posted by desjardins at 9:40 AM on May 20, 2011 [1 favorite]\n",
      "\n",
      "At Elliot Bay Marina, the Seattle Yacht Club has classes in everything from sailing to kayaking to windsurfing. But, as beccaj says, Alki Beach is the most convenient and is a great place to learn to surf.\n",
      "posted by Zed_Lopez at 9:52 AM on May 20, 2011\n",
      "\n",
      "Windsurfing is great fun. You don't need to spend a lot of money to get started, either. You can rent a windsurf board and sail for $20/hour and $50/day at the Alki Beach Windsurfing School. They also rent wetsuits for $10/day. If you want to learn to windsurf, this\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name='davinci-002')\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template ='''\n",
    "I really want to do {activity} today. How do I get started?\n",
    "I live in {location}.\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(input_variables = ['activity', 'location'],\n",
    "                        template = template)\n",
    "\n",
    "final_prompt = prompt.format(activity='surfing', location='Seattle')\n",
    "\n",
    "print(final_prompt)\n",
    "print('*'*40)\n",
    "print(f'LLM: {llm(final_prompt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Example Input: {input}\\nExample Output: {output}\",\n",
    ")\n",
    "\n",
    "# Examples of locations that nouns are found\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
    "    {\"input\": \"pilot\", \"output\": \"plane\"},\n",
    "    {\"input\": \"driver\", \"output\": \"car\"},\n",
    "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
    "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    OpenAIEmbeddings(),#Embedding \n",
    "    Chroma,#Vector store\n",
    "    k = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the location an item is usually found in\",\n",
    "    suffix = \"Input: {noun}\\nOutput:\",\n",
    "    input_variables=[\"noun\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the location an item is usually found in\n",
      "\n",
      "Example Input: driver\n",
      "Example Output: car\n",
      "\n",
      "Example Input: pilot\n",
      "Example Output: plane\n",
      "\n",
      "Input: student\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "my_noun = \"student\"\n",
    "\n",
    "print(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' school\\n\\nIf you can’t get a straight answer out of the user, the program should force the user to enter something again, but don’t just keep repeating the question, that’s annoying!\\n\\nIf you’re stuck, try asking your question in a slightly different way. If you’re still stuck, try asking a different question.\\n\\nAlso, don’t let the user enter more than one word at a time, and don’t let them enter spaces. This is a single word search that you’re doing.\\n\\nIf the user enters a word that isn’t in the dictionary, have them enter something again. I considered doing this in the previous problem, but I thought that was a little too harsh.\\n\\nIf you get tired of finding words in the dictionary, you can search the Bible or a book instead. Just have the user enter the name of the book or Bible chapter and verse.\\n\\nExample Input: bible\\nExample Output:\\n    Genesis 1:2\\n    John 1:1\\n    Proverbs 3:5\\n    Mark 12:31\\n\\nExample Input: Genesis 1:2\\nExample Output: “Then the earth was formless and empty, and darkness covered the deep waters.” (NLT)\\n\\nYou can use this as an opportunity to exercise your'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(model_name='davinci-002')\n",
    "llm(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]\n",
    "\n",
    "# How you would like to parse your output\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print (format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a poorly formatted string from a user.\n",
      "Reformat it and make sure all the words are spelled correctly\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n",
      "\n",
      "% USER INPUT:\n",
      "welcom to califonya!\n",
      "\n",
      "YOUR RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT:\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "promptValue = prompt.format(user_input=\"welcom to califonya!\")\n",
    "\n",
    "print(promptValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n\\t\"bad_string\": \"welcom to califonya!\",\\n\\t\"good_string\": \"Welcome to California!\"\\n}\\n```'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_output = llm(promptValue)\n",
    "llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad_string': 'welcom to califonya!', 'good_string': 'Welcome to California!'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Identifying information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The person's name\")\n",
    "    age: int = Field(..., description=\"The person's age\")\n",
    "    fav_food: Optional[str] = Field(None, description=\"The person's favorite food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wes = Person(name=\"Wes\", age=30, taco = \"taco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:115: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Person(name='Sally, Joey, Caroline', age=13, fav_food='spinach')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.openai_functions import create_structured_output_chain\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-0613')\n",
    "\n",
    "chain = create_structured_output_chain(Person, llm, prompt)\n",
    "chain.run(\n",
    "    \"Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: Sequence[Person] = Field(..., description=\"The people in the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Sally', age=13, fav_food='Unknown'), Person(name='Joey', age=12, fav_food='spinach'), Person(name='Caroline', age=23, fav_food='Unknown')])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = create_structured_output_chain(People, llm, prompt)\n",
    "chain.run(\n",
    "    \"Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum \n",
    "\n",
    "class Product(str, enum.Enum):\n",
    "    \"\"\"A product that can be purchased.\"\"\"\n",
    "\n",
    "    COFFEE = \"coffee\"\n",
    "    TEA = \"tea\"\n",
    "    SMOOTHIE = \"smoothie\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Products(BaseModel):\n",
    "    \"\"\"Identifying products that were mentioned in a text\"\"\"\n",
    "\n",
    "    products: Sequence[Product] = Field(..., description=\"The products mentioned in a text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Products(products=[<Product.COFFEE: 'coffee'>, <Product.TEA: 'tea'>, <Product.SMOOTHIE: 'smoothie'>])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = create_structured_output_chain(Products, llm, prompt)\n",
    "chain.run(\"The coffee was good, but the tea was better. I didn't like the smoothie. I hated the chocolate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HNLoader\n",
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=34422627\")\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 comments\n",
      "Here's a sample:\n",
      "\n",
      "Ozzie_osman 11 months ago  \n",
      "             | next [–] \n",
      "\n",
      "LangChain is awesome. For people not sure what it's doing, large language models (LLMs) are veryOzzie_osman 11 months ago  \n",
      "             | parent | next [–] \n",
      "\n",
      "Also, another library to check out is GPT Index (https://github.com/jerryjliu/gpt_index\n"
     ]
    }
   ],
   "source": [
    "print (f\"Found {len(data)} comments\")\n",
    "print (f\"Here's a sample:\\n\\n{''.join([x.page_content[:150] for x in data[:2]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n"
     ]
    }
   ],
   "source": [
    "# This is a long document we can split up.\n",
    "with open('worked.txt') as f:\n",
    "    pg_work = f.read()\n",
    "    \n",
    "print (f\"You have {len([pg_work])} document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap  = 20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([pg_work])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 610 documents\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:\n",
      "February 2021Before college the two main things I worked on, outside of school,\n",
      "were writing and programming. I didn't write essays. I wrote what \n",
      "\n",
      "beginning writers were supposed to write then, and probably still\n",
      "are: short stories. My stories were awful. They had hardly any plot,\n"
     ]
    }
   ],
   "source": [
    "print (\"Preview:\")\n",
    "print (texts[0].page_content, \"\\n\")\n",
    "print (texts[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('worked.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Get embedding engine ready\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Embedd your texts\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025C840DAE50>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"what types of things did the author want to build?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"standards; what was the point? No one else wanted one either, so\\noff they went. That was what happened to systems work.I wanted not just to build things, but to build things that would\\nlast.In this dissatisfied state I went in 1988 to visit Rich Draves at\\nCMU, where he was in grad school. One day I went to visit the\\nCarnegie Institute, where I'd spent a lot of time as a kid. While\\nlooking at a painting there I realized something that might seem\\nobvious, but was a big surprise to me. There, right on the wall,\\nwas something you could make that would last. Paintings didn't\\nbecome obsolete. Some of the best ones were hundreds of years old.And moreover this was something you could make a living doing. Not\\nas easily as you could by writing software, of course, but I thought\\nif you were really industrious and lived really cheaply, it had to\\nbe possible to make enough to survive. And as an artist you could\\nbe truly independent. You wouldn't have a boss, or even need to get\", metadata={'source': 'worked.txt'}),\n",
       " Document(page_content=\"infrastructure, and the two undergrads worked on the first two\\nservices (images and phone calls). But about halfway through the\\nsummer I realized I really didn't want to run a company Â— especially\\nnot a big one, which it was looking like this would have to be. I'd\\nonly started Viaweb because I needed the money. Now that I didn't\\nneed money anymore, why was I doing this? If this vision had to be\\nrealized as a company, then screw the vision. I'd build a subset\\nthat could be done as an open source project.Much to my surprise, the time I spent working on this stuff was not\\nwasted after all. After we started Y Combinator, I would often\\nencounter startups working on parts of this new architecture, and\\nit was very useful to have spent so much time thinking about it and\\neven trying to write some of it.The subset I would build as an open source project was the new Lisp,\\nwhose parentheses I now wouldn't even have to hide. A lot of Lisp\", metadata={'source': 'worked.txt'}),\n",
       " Document(page_content=\"much of it in grad school.Computer Science is an uneasy alliance between two halves, theory\\nand systems. The theory people prove things, and the systems people\\nbuild things. I wanted to build things. I had plenty of respect for\\ntheory Â— indeed, a sneaking suspicion that it was the more admirable\\nof the two halves Â— but building things seemed so much more exciting.The problem with systems work, though, was that it didn't last.\\nAny program you wrote today, no matter how good, would be obsolete\\nin a couple decades at best. People might mention your software in\\nfootnotes, but no one would actually use it. And indeed, it would\\nseem very feeble work. Only people with a sense of the history of\\nthe field would even realize that, in its time, it had been good.There were some surplus Xerox Dandelions floating around the computer\\nlab at one point. Anyone who wanted one to play around with could\\nhave one. I was briefly tempted, but they were so slow by present\", metadata={'source': 'worked.txt'}),\n",
       " Document(page_content='been generating for galleries. This impressive-sounding thing called\\nan \"internet storefront\" was something we already knew how to build.So in the summer of 1995, after I submitted the camera-ready copy\\nof ANSI Common Lisp to the publishers, we started trying to write\\nsoftware to build online stores. At first this was going to be\\nnormal desktop software, which in those days meant Windows software.\\nThat was an alarming prospect, because neither of us knew how to\\nwrite Windows software or wanted to learn. We lived in the Unix\\nworld. But we decided we\\'d at least try writing a prototype store\\nbuilder on Unix. Robert wrote a shopping cart, and I wrote a new\\nsite generator for stores Â— in Lisp, of course.We were working out of Robert\\'s apartment in Cambridge. His roommate\\nwas away for big chunks of time, during which I got to sleep in his\\nroom. For some reason there was no bed frame or sheets, just a\\nmattress on the floor. One morning as I was lying on this mattress', metadata={'source': 'worked.txt'})]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standards; what was the point? No one else wanted one either, so\n",
      "off they went. That was what happened to systems work.I wanted not just to build things, but to build things that would\n",
      "last.In this di\n",
      "\n",
      "infrastructure, and the two undergrads worked on the first two\n",
      "services (images and phone calls). But about halfway through the\n",
      "summer I realized I really didn't want to run a company Â— especially\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([x.page_content[:200] for x in docs[:2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector stores\n",
    "\n",
    "embeddings and metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader('worked.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Get embedding engine ready\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 78 documents\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = embeddings.embed_documents([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='February 2021Before college the two main things I worked on, outside of school,\\nwere writing and programming. I didn\\'t write essays. I wrote what\\nbeginning writers were supposed to write then, and probably still\\nare: short stories. My stories were awful. They had hardly any plot,\\njust characters with strong feelings, which I imagined made them\\ndeep.The first programs I tried writing were on the IBM 1401 that our\\nschool district used for what was then called \"data processing.\"\\nThis was in 9th grade, so I was 13 or 14. The school district\\'s\\n1401 happened to be in the basement of our junior high school, and\\nmy friend Rich Draves and I got permission to use it. It was like\\na mini Bond villain\\'s lair down there, with all these alien-looking\\nmachines Â— CPU, disk drives, printer, card reader Â— sitting up\\non a raised floor under bright fluorescent lights.The language we used was an early version of Fortran. You had to\\ntype programs on punch cards, then stack them in the card reader', metadata={'source': 'worked.txt'}),\n",
       " Document(page_content=\"and press a button to load the program into memory and run it. The\\nresult would ordinarily be to print something on the spectacularly\\nloud printer.I was puzzled by the 1401. I couldn't figure out what to do with\\nit. And in retrospect there's not much I could have done with it.\\nThe only form of input to programs was data stored on punched cards,\\nand I didn't have any data stored on punched cards. The only other\\noption was to do things that didn't rely on any input, like calculate\\napproximations of pi, but I didn't know enough math to do anything\\ninteresting of that type. So I'm not surprised I can't remember any\\nprograms I wrote, because they can't have done much. My clearest\\nmemory is of the moment I learned it was possible for programs not\\nto terminate, when one of mine didn't. On a machine without\\ntime-sharing, this was a social as well as a technical error, as\\nthe data center manager's expression made clear.With microcomputers, everything changed. Now you could have a\", metadata={'source': 'worked.txt'})]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 78 embeddings\n",
      "Here's a sample of one: [-0.001083008393785737, -0.01087374061141683, -0.012754313571672412]...\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(embedding_list)} embeddings\")\n",
    "print (f\"Here's a sample of one: {embedding_list[0][:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-stuff-DMV5Iwx5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
