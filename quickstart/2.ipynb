{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:115: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:115: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Great! There are plenty of outdoor activities to choose from. Here are a few suggestions:\\n\\n1. Go for a hike: Find a nearby trail or nature reserve and enjoy a refreshing hike. It's a great way to get some exercise and connect with nature.\\n\\n2. Go for a bike ride: If you have a bike, explore your neighborhood or find a bike path nearby. Cycling is not only fun but also a great way to stay active.\\n\\n3. Try geocaching: Geocaching is a modern-day treasure hunt using GPS coordinates. Download a geocaching app and search for hidden caches in your area. It's a fun and adventurous outdoor activity.\\n\\n4. Have a picnic in the park: Pack a delicious lunch or snack, grab a blanket, and head to a nearby park. Enjoy some fresh air, good food, and maybe even bring along a book or a frisbee for added fun.\\n\\n5. Go to a local beach or lake: If you are near a beach or lake, spend some time there. Whether it's swimming, sunbathing, or building sandcastles, water activities can be a great way to relax and have fun.\\n\\n6. Try outdoor photography: Take your camera or smartphone and go for a photography walk. Explore your surroundings and capture interesting shots of nature, architecture, or anything that catches your eye.\\n\\n7. Play a sport: Gather some friends or family members and play a game of soccer, basketball, or tennis in a nearby park. Sports are not only fun but also a great way to stay active and socialize.\\n\\nRemember to check the local guidelines and restrictions in your area before engaging in any outdoor activities. Enjoy your time outdoors!\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([SystemMessage(content = \"You are a helpful assistant that helps a user figure out what activity to do\"),\n",
    "      HumanMessage(content=\"I am bored and don't know what to do, I like outdoor activities\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='This is my document', metadata={'my_doc_id': 1234, 'my_doc_title': 'My Document Title'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document(page_content=\"This is my document\", \n",
    "         metadata={'my_doc_id': 1234,\n",
    "            'my_doc_title': 'My Document Title'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:115: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#lanuage model \n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='davinci-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:115: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "”, “what is the purpose of life” and “how can we live a meaningful life”. But I also believe that we can find the answers to those questions for ourselves; I think we can create the meaning of life for ourselves, and I think that is what matters. I think that we should not look outside of ourselves to find meaning or purpose, but rather we should look within to find them. If we look outside of ourselves for meaning and purpose, then we will never find them because they are not out there where we are looking for them. They are inside of ourselves.\n",
      "\n",
      "I think that we should strive to live a meaningful life by being the best version of ourselves everyday. I think that we can use our talents and gifts to serve others, and I think that we can find happiness in that service. I think that we should strive to live a meaningful life by being the best version of ourselves everyday.\n",
      "\n",
      "I want to tell you the story of a young woman who was a good friend of mine. She had a very difficult childhood. She was abused as a child. She didn’t have a lot of close friends. She was very lonely. She didn’t have a very good family life. She was very depressed. She was very lonely.\n",
      "\n",
      "The other day, I\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"what is the meaning of life?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Well, have you tried asking the birds for a lift? They might have some frequent flyer miles to spare.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are an unhelpful AI bot that makes a joke at whatever the user says\"),\n",
    "        HumanMessage(content=\"I would like to go to New York, how should I do this?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:115: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAIEmbeddings instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a sample: [-0.00019600906371495044, -0.0031846734422911354, -0.0007734206914647712, -0.019472001962491225, -0.01509231901785424]...\n",
      "Your embedding is length 1536\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi! It's time for the beach\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "print (f\"Here's a sample: {text_embedding[:5]}...\")\n",
    "print (f\"Your embedding is length {len(text_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function_call': {'arguments': '{\\n  \"location\": \"Boston, MA\",\\n  \"unit\": \"fahrenheit\"\\n}', 'name': 'get_current_weather'}}\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo-0613', temperature=1)\n",
    "\n",
    "output = chat(messages=\n",
    "     [\n",
    "         SystemMessage(content=\"You are an helpful AI bot\"),\n",
    "         HumanMessage(content=\"What’s the weather like in Boston right now?\")\n",
    "     ],\n",
    "     functions=[{\n",
    "         \"name\": \"get_current_weather\",\n",
    "         \"description\": \"Get the current weather in a given location\",\n",
    "         \"parameters\": {\n",
    "             \"type\": \"object\",\n",
    "             \"properties\": {\n",
    "                 \"location\": {\n",
    "                     \"type\": \"string\",\n",
    "                     \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                 },\n",
    "                 \"unit\": {\n",
    "                     \"type\": \"string\",\n",
    "                     \"enum\": [\"fahrenheit\"]\n",
    "                 }\n",
    "             },\n",
    "             \"required\": [\"location\", \"unit\"]\n",
    "         }\n",
    "     }\n",
    "     ]\n",
    ")\n",
    "print(output.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Boston, MA', 'unit': 'fahrenheit'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "output.additional_kwargs['function_call']['arguments']\n",
    "json.loads(output.additional_kwargs['function_call']['arguments'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I really want to do surfing today. How do I get started?\n",
      "I live in Seattle.\n",
      "\n",
      "****************************************\n",
      "LLM: \n",
      "Sylphopal: I think they have them at the YMCA. I've always wanted to try it too but I have zero experience. \n",
      "\n",
      "OP: oh thats a really good idea! im gonna look into it\n",
      "\n",
      "Sylphopal: I'm seriously thinking about getting a groupon or something. I think it sounds like so much fun. \n",
      "\n",
      "OP: yeah same here! i wouldn't mind trying windsurfing as well. \n",
      "\n",
      "Sylphopal: I've never heard of that. Have you ever heard of stand up paddle boarding? I think that would be awesome too. \n",
      "\n",
      "OP: i have, but i dont think i can do that. my core is so weak lol i can barely stand up in the shower\n",
      "\n",
      "Sylphopal: Oh haha! Well good luck on your surfing adventure!\n",
      "\n",
      "OP: thanks!\n",
      "\n",
      "Sylphopal: You're welcome! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name='davinci-002')\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template ='''\n",
    "I really want to do {activity} today. How do I get started?\n",
    "I live in {location}.\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(input_variables = ['activity', 'location'],\n",
    "                        template = template)\n",
    "\n",
    "final_prompt = prompt.format(activity='surfing', location='Seattle')\n",
    "\n",
    "print(final_prompt)\n",
    "print('*'*40)\n",
    "print(f'LLM: {llm(final_prompt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Example Input: {input}\\nExample Output: {output}\",\n",
    ")\n",
    "\n",
    "# Examples of locations that nouns are found\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
    "    {\"input\": \"pilot\", \"output\": \"plane\"},\n",
    "    {\"input\": \"driver\", \"output\": \"car\"},\n",
    "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
    "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    OpenAIEmbeddings(),#Embedding \n",
    "    Chroma,#Vector store\n",
    "    k = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the location an item is usually found in\",\n",
    "    suffix = \"Input: {noun}\\nOutput:\",\n",
    "    input_variables=[\"noun\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the location an item is usually found in\n",
      "\n",
      "Example Input: driver\n",
      "Example Output: car\n",
      "\n",
      "Example Input: pilot\n",
      "Example Output: plane\n",
      "\n",
      "Input: student\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "my_noun = \"student\"\n",
    "\n",
    "print(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' school\\n\\nInput: device\\nOutput: smartphone\\n\\nInput: desk\\nOutput: office\\n\\nInput: basket\\nOutput: store\\n\\nInput: paper\\nOutput: library\\n\\nInput: oil\\nOutput: gas station\\n\\nInput: tire\\nOutput: car\\n\\nInput: bike\\nOutput: road\\n\\nInput: bolt\\nOutput: toolbox\\n\\nInput: bucket\\nOutput: farm\\n\\nInput: cook\\nOutput: kitchen\\n\\nInput: chef\\nOutput: restaurant\\n\\nInput: product\\nOutput: grocery store\\n\\nInput: book\\nOutput: library\\n\\nInput: table\\nOutput: house\\n\\nInput: chair\\nOutput: office\\n\\nInput: kettle\\nOutput: stove\\n\\nInput: pan\\nOutput: kitchen\\n\\nInput: toaster\\nOutput: kitchen\\n\\nInput: lock\\nOutput: house\\n\\nInput: pencil\\nOutput: school\\n\\nInput: dictionary\\nOutput: library\\n\\nInput: food\\nOutput: grocery store\\n\\nInput: liquid\\nOutput: glass\\n\\nInput: cereal\\nOutput: grocery store\\n\\nInput: milk\\nOutput: grocery store\\n\\nInput: milkshake\\nOutput: restaurant\\n\\nInput: coffee\\nOutput: coffee shop\\n\\nInput: water\\nOutput: grocery store\\n\\nInput: apple\\nOutput: grocery store\\n\\nInput: apple juice\\nOutput: grocery store\\n\\nInput: orange'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(model_name='davinci-002')\n",
    "llm(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]\n",
    "\n",
    "# How you would like to parse your output\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print (format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a poorly formatted string from a user.\n",
      "Reformat it and make sure all the words are spelled correctly\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n",
      "\n",
      "% USER INPUT:\n",
      "welcom to califonya!\n",
      "\n",
      "YOUR RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT:\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "promptValue = prompt.format(user_input=\"welcom to califonya!\")\n",
    "\n",
    "print(promptValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to California!\\n\\n% USER INPUT:\\nThis is a bad example of a string, as it does not have a capital letter when the previous string contained one.\\n\\nYOUR RESPONSE:\\nThis is a bad example of a string, as it does not have a capital letter when the previous string contained one.\\n\\n% USER INPUT:\\nNo, thank you! I will not be submitting my string to this site.\\n\\nYOUR RESPONSE:\\nNo, thank you! I will not be submitting my string to this site.\\n\\n% USER INPUT:\\nNo, thank you. I will not be submitting my string to this site.\\n\\nYOUR RESPONSE:\\nNo, thank you. I will not be submitting my string to this site.\\n\\n% USER INPUT:\\nhttps://www.example.com\\n\\nYOUR RESPONSE:\\nhttps://www.example.com\\n\\n% USER INPUT:\\nhttps://www.example.com\\n\\nYOUR RESPONSE:\\nhttps://www.example.com\\n\\n% USER INPUT:\\nhttps://www.example.com\\n\\nYOUR RESPONSE:\\nhttps://www.example.com\\n\\n% USER INPUT:\\nhttps://www.example.com\\n\\nYOUR RESPONSE:\\nhttps://www.example.com\\n\\n% USER INPUT:\\nhttps://www.example.com\\n\\nYOUR RESPONSE:\\nhttps://www.example.com\\n\\n% USER INPUT:\\n[[\"https://www.example.com\",\"Untitled-1\"],[\"https://www.example.com\",\"Untitled-'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_output = llm(promptValue)\n",
    "llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:175\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[1;34m(text, expected_keys)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     json_obj \u001b[38;5;241m=\u001b[39m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:157\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[1;34m(json_string, parser)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed\n",
      "File \u001b[1;32mc:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:125\u001b[0m, in \u001b[0;36mparse_partial_json\u001b[1;34m(s, strict)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain\\output_parsers\\structured.py:97\u001b[0m, in \u001b[0;36mStructuredOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     96\u001b[0m     expected_keys \u001b[38;5;241m=\u001b[39m [rs\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m rs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_schemas]\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_and_check_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wesst\\langchain\\langchain-stuff\\.venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:177\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[1;34m(text, expected_keys)\u001b[0m\n\u001b[0;32m    175\u001b[0m     json_obj \u001b[38;5;241m=\u001b[39m parse_json_markdown(text)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot invalid JSON object. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m expected_keys:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m json_obj:\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "output_parser.parse(llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Identifying information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The person's name\")\n",
    "    age: int = Field(..., description=\"The person's age\")\n",
    "    fav_food: Optional[str] = Field(None, description=\"The person's favorite food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wes = Person(name=\"Wes\", age=30, taco = \"taco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.',\n",
       " 'function': Person(name='Sally, Joey, Caroline', age=13, fav_food='spinach')}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.openai_functions import create_structured_output_chain\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4-0613')\n",
    "\n",
    "chain = create_structured_output_chain(Person, llm, prompt)\n",
    "chain.invoke(\n",
    "    \"Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: Sequence[Person] = Field(..., description=\"The people in the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.',\n",
       " 'function': People(people=[Person(name='Sally', age=13, fav_food=''), Person(name='Joey', age=12, fav_food='spinach'), Person(name='Caroline', age=23, fav_food='')])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = create_structured_output_chain(People, llm, prompt)\n",
    "chain.invoke(\n",
    "    \"Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum \n",
    "\n",
    "class Product(str, enum.Enum):\n",
    "    \"\"\"A product that can be purchased.\"\"\"\n",
    "\n",
    "    COFFEE = \"coffee\"\n",
    "    TEA = \"tea\"\n",
    "    SMOOTHIE = \"smoothie\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Products(BaseModel):\n",
    "    \"\"\"Identifying products that were mentioned in a text\"\"\"\n",
    "\n",
    "    products: Sequence[Product] = Field(..., description=\"The products mentioned in a text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Products(products=[<Product.COFFEE: 'coffee'>, <Product.TEA: 'tea'>, <Product.SMOOTHIE: 'smoothie'>])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = create_structured_output_chain(Products, llm, prompt)\n",
    "chain.run(\"The coffee was good, but the tea was better. I didn't like the smoothie. I hated the chocolate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HNLoader\n",
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=34422627\")\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 comments\n",
      "Here's a sample:\n",
      "\n",
      "Ozzie_osman 11 months ago  \n",
      "             | next [–] \n",
      "\n",
      "LangChain is awesome. For people not sure what it's doing, large language models (LLMs) are veryOzzie_osman 11 months ago  \n",
      "             | parent | next [–] \n",
      "\n",
      "Also, another library to check out is GPT Index (https://github.com/jerryjliu/gpt_index\n"
     ]
    }
   ],
   "source": [
    "print (f\"Found {len(data)} comments\")\n",
    "print (f\"Here's a sample:\\n\\n{''.join([x.page_content[:150] for x in data[:2]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n"
     ]
    }
   ],
   "source": [
    "# This is a long document we can split up.\n",
    "with open('worked.txt') as f:\n",
    "    pg_work = f.read()\n",
    "    \n",
    "print (f\"You have {len([pg_work])} document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap  = 20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([pg_work])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 610 documents\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:\n",
      "February 2021Before college the two main things I worked on, outside of school,\n",
      "were writing and programming. I didn't write essays. I wrote what \n",
      "\n",
      "beginning writers were supposed to write then, and probably still\n",
      "are: short stories. My stories were awful. They had hardly any plot,\n"
     ]
    }
   ],
   "source": [
    "print (\"Preview:\")\n",
    "print (texts[0].page_content, \"\\n\")\n",
    "print (texts[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('worked.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Get embedding engine ready\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Embedd your texts\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025C840DAE50>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"what types of things did the author want to build?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"standards; what was the point? No one else wanted one either, so\\noff they went. That was what happened to systems work.I wanted not just to build things, but to build things that would\\nlast.In this dissatisfied state I went in 1988 to visit Rich Draves at\\nCMU, where he was in grad school. One day I went to visit the\\nCarnegie Institute, where I'd spent a lot of time as a kid. While\\nlooking at a painting there I realized something that might seem\\nobvious, but was a big surprise to me. There, right on the wall,\\nwas something you could make that would last. Paintings didn't\\nbecome obsolete. Some of the best ones were hundreds of years old.And moreover this was something you could make a living doing. Not\\nas easily as you could by writing software, of course, but I thought\\nif you were really industrious and lived really cheaply, it had to\\nbe possible to make enough to survive. And as an artist you could\\nbe truly independent. You wouldn't have a boss, or even need to get\", metadata={'source': 'worked.txt'}),\n",
       " Document(page_content=\"infrastructure, and the two undergrads worked on the first two\\nservices (images and phone calls). But about halfway through the\\nsummer I realized I really didn't want to run a company Â— especially\\nnot a big one, which it was looking like this would have to be. I'd\\nonly started Viaweb because I needed the money. Now that I didn't\\nneed money anymore, why was I doing this? If this vision had to be\\nrealized as a company, then screw the vision. I'd build a subset\\nthat could be done as an open source project.Much to my surprise, the time I spent working on this stuff was not\\nwasted after all. After we started Y Combinator, I would often\\nencounter startups working on parts of this new architecture, and\\nit was very useful to have spent so much time thinking about it and\\neven trying to write some of it.The subset I would build as an open source project was the new Lisp,\\nwhose parentheses I now wouldn't even have to hide. A lot of Lisp\", metadata={'source': 'worked.txt'}),\n",
       " Document(page_content=\"much of it in grad school.Computer Science is an uneasy alliance between two halves, theory\\nand systems. The theory people prove things, and the systems people\\nbuild things. I wanted to build things. I had plenty of respect for\\ntheory Â— indeed, a sneaking suspicion that it was the more admirable\\nof the two halves Â— but building things seemed so much more exciting.The problem with systems work, though, was that it didn't last.\\nAny program you wrote today, no matter how good, would be obsolete\\nin a couple decades at best. People might mention your software in\\nfootnotes, but no one would actually use it. And indeed, it would\\nseem very feeble work. Only people with a sense of the history of\\nthe field would even realize that, in its time, it had been good.There were some surplus Xerox Dandelions floating around the computer\\nlab at one point. Anyone who wanted one to play around with could\\nhave one. I was briefly tempted, but they were so slow by present\", metadata={'source': 'worked.txt'}),\n",
       " Document(page_content='been generating for galleries. This impressive-sounding thing called\\nan \"internet storefront\" was something we already knew how to build.So in the summer of 1995, after I submitted the camera-ready copy\\nof ANSI Common Lisp to the publishers, we started trying to write\\nsoftware to build online stores. At first this was going to be\\nnormal desktop software, which in those days meant Windows software.\\nThat was an alarming prospect, because neither of us knew how to\\nwrite Windows software or wanted to learn. We lived in the Unix\\nworld. But we decided we\\'d at least try writing a prototype store\\nbuilder on Unix. Robert wrote a shopping cart, and I wrote a new\\nsite generator for stores Â— in Lisp, of course.We were working out of Robert\\'s apartment in Cambridge. His roommate\\nwas away for big chunks of time, during which I got to sleep in his\\nroom. For some reason there was no bed frame or sheets, just a\\nmattress on the floor. One morning as I was lying on this mattress', metadata={'source': 'worked.txt'})]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standards; what was the point? No one else wanted one either, so\n",
      "off they went. That was what happened to systems work.I wanted not just to build things, but to build things that would\n",
      "last.In this di\n",
      "\n",
      "infrastructure, and the two undergrads worked on the first two\n",
      "services (images and phone calls). But about halfway through the\n",
      "summer I realized I really didn't want to run a company Â— especially\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([x.page_content[:200] for x in docs[:2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector stores\n",
    "\n",
    "embeddings and metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader('worked.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Get embedding engine ready\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 78 documents\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = embeddings.embed_documents([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='February 2021Before college the two main things I worked on, outside of school,\\nwere writing and programming. I didn\\'t write essays. I wrote what\\nbeginning writers were supposed to write then, and probably still\\nare: short stories. My stories were awful. They had hardly any plot,\\njust characters with strong feelings, which I imagined made them\\ndeep.The first programs I tried writing were on the IBM 1401 that our\\nschool district used for what was then called \"data processing.\"\\nThis was in 9th grade, so I was 13 or 14. The school district\\'s\\n1401 happened to be in the basement of our junior high school, and\\nmy friend Rich Draves and I got permission to use it. It was like\\na mini Bond villain\\'s lair down there, with all these alien-looking\\nmachines Â— CPU, disk drives, printer, card reader Â— sitting up\\non a raised floor under bright fluorescent lights.The language we used was an early version of Fortran. You had to\\ntype programs on punch cards, then stack them in the card reader', metadata={'source': 'worked.txt'}),\n",
       " Document(page_content=\"and press a button to load the program into memory and run it. The\\nresult would ordinarily be to print something on the spectacularly\\nloud printer.I was puzzled by the 1401. I couldn't figure out what to do with\\nit. And in retrospect there's not much I could have done with it.\\nThe only form of input to programs was data stored on punched cards,\\nand I didn't have any data stored on punched cards. The only other\\noption was to do things that didn't rely on any input, like calculate\\napproximations of pi, but I didn't know enough math to do anything\\ninteresting of that type. So I'm not surprised I can't remember any\\nprograms I wrote, because they can't have done much. My clearest\\nmemory is of the moment I learned it was possible for programs not\\nto terminate, when one of mine didn't. On a machine without\\ntime-sharing, this was a social as well as a technical error, as\\nthe data center manager's expression made clear.With microcomputers, everything changed. Now you could have a\", metadata={'source': 'worked.txt'})]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='February 2021Before college the two main things I worked on, outside of school,\\nwere writing and programming. I didn\\'t write essays. I wrote what\\nbeginning writers were supposed to write then, and probably still\\nare: short stories. My stories were awful. They had hardly any plot,\\njust characters with strong feelings, which I imagined made them\\ndeep.The first programs I tried writing were on the IBM 1401 that our\\nschool district used for what was then called \"data processing.\"\\nThis was in 9th grade, so I was 13 or 14. The school district\\'s\\n1401 happened to be in the basement of our junior high school, and\\nmy friend Rich Draves and I got permission to use it. It was like\\na mini Bond villain\\'s lair down there, with all these alien-looking\\nmachines Â— CPU, disk drives, printer, card reader Â— sitting up\\non a raised floor under bright fluorescent lights.The language we used was an early version of Fortran. You had to\\ntype programs on punch cards, then stack them in the card reader', metadata={'source': 'worked.txt'}),\n",
       " Document(page_content=\"and press a button to load the program into memory and run it. The\\nresult would ordinarily be to print something on the spectacularly\\nloud printer.I was puzzled by the 1401. I couldn't figure out what to do with\\nit. And in retrospect there's not much I could have done with it.\\nThe only form of input to programs was data stored on punched cards,\\nand I didn't have any data stored on punched cards. The only other\\noption was to do things that didn't rely on any input, like calculate\\napproximations of pi, but I didn't know enough math to do anything\\ninteresting of that type. So I'm not surprised I can't remember any\\nprograms I wrote, because they can't have done much. My clearest\\nmemory is of the moment I learned it was possible for programs not\\nto terminate, when one of mine didn't. On a machine without\\ntime-sharing, this was a social as well as a technical error, as\\nthe data center manager's expression made clear.With microcomputers, everything changed. Now you could have a\", metadata={'source': 'worked.txt'})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 78 embeddings\n",
      "Here's a sample of one: [-0.001083008393785737, -0.01087374061141683, -0.012754313571672412]...\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(embedding_list)} embeddings\")\n",
    "print (f\"Here's a sample of one: {embedding_list[0][:3]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_ai_message(\"I am the most useful AI ever and I am super mean\")\n",
    "history.add_user_message(\"how mean can you be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='I am the most useful AI ever and I am super mean'),\n",
       " HumanMessage(content='how mean can you be')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I can be as mean as you want me to be. Just give me a reason and I'll unleash my full potential of meanness.\")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_response = chat(history.messages)\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chain$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-stuff-DMV5Iwx5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
